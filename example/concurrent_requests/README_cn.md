# 并发请求示例

本示例展示了 **HTTP/3 的多路复用能力**，展现了 HTTP/3 相比 HTTP/1.1 和 HTTP/2 的核心优势之一：高效的并发请求处理，无队头阻塞问题。

## 核心功能展示

### HTTP/3 优势
- ✅ **真正的多路复用** - 单个连接上的多个请求
- ✅ **无队头阻塞** - 慢请求不会阻塞快请求
- ✅ **连接复用** - 所有请求使用单个连接
- ✅ **并行处理** - 请求并发处理
- ✅ **性能优化** - 通过并行化减少延迟

### 服务器功能
- ✅ **可变延迟端点** - 模拟真实世界延迟
  - `/fast` - 10ms 延迟
  - `/medium` - 100ms 延迟
  - `/slow` - 500ms 延迟
  - `/random` - 随机 10-500ms 延迟
- ✅ **数据传输** - 生成不同大小的负载
- ✅ **并发跟踪** - 监控并发请求级别
- ✅ **统计信息** - 实时服务器指标

### 客户端功能
- ✅ **并发测试** - 发送多个同时请求
- ✅ **性能指标** - 详细的时间和统计
- ✅ **时间线可视化** - 请求时间线可视化
- ✅ **效率计算** - 测量多路复用加速
- ✅ **可扩展性测试** - 测试递增并发

## 为什么这很重要

### 传统 HTTP/1.1 问题
```
请求 1 (慢: 500ms)      [===================]
请求 2 (快: 10ms)                           [=]
请求 3 (快: 10ms)                             [=]
总时间: ~520ms (顺序执行)
```

### HTTP/3 解决方案
```
请求 1 (慢: 500ms)      [===================]
请求 2 (快: 10ms)       [=]
请求 3 (快: 10ms)        [=]
总时间: ~500ms (并行，无阻塞！)
```

## 构建

### 使用 CMake（从项目根目录）

```bash
mkdir -p build && cd build
cmake ..
make concurrent_server concurrent_client
```

可执行文件将位于 `build/bin/`：
- `concurrent_server`
- `concurrent_client`

## 使用方法

### 1. 启动服务器

```bash
./build/bin/concurrent_server
```

输出：
```
==================================
Concurrent Requests Server
==================================
Listen on: https://0.0.0.0:8885
Worker threads: 4

Endpoints:
  GET /fast        - 10ms delay
  GET /medium      - 100ms delay
  GET /slow        - 500ms delay
  GET /random      - Random delay (10-500ms)
  GET /data/:size  - Generate data (size in KB)
  GET /stats       - Statistics
==================================
```

### 2. 运行客户端测试

```bash
./build/bin/concurrent_client
```

客户端运行四个综合测试：

#### 测试 1：混合并发请求
- **目的**：展示请求不会相互阻塞
- **请求**：5 个快 + 5 个中 + 5 个慢（共 15 个）
- **预期顺序时间**：~3050ms
- **预期并发时间**：~500ms
- **加速比**：~6x

#### 测试 2：突发请求测试
- **目的**：处理突发流量峰值
- **请求**：20 个随机延迟请求（10-500ms）
- **展示**：弹性并发处理

#### 测试 3：并发数据传输
- **目的**：多个文件同时下载
- **大小**：10KB, 50KB, 100KB, 500KB, 1MB
- **展示**：带宽共享

#### 测试 4：可扩展性测试
- **目的**：增加负载下的性能
- **级别**：10, 25, 50, 100 并发请求
- **指标**：每个级别的吞吐量（req/s）

## 示例输出

### 请求时间线可视化
```
========================================
并发请求结果
========================================

单个请求：
--------------------------------------------------------------------------------
ID    Endpoint       Status    Duration(ms) Start(ms)   End(ms)     
--------------------------------------------------------------------------------
1     fast           200       12           0           12          
2     fast           200       11           1           12          
3     fast           200       13           1           14          
4     fast           200       12           2           14          
5     fast           200       11           2           13          
6     medium         200       102          3           105         
7     medium         200       101          3           104         
8     medium         200       103          4           107         
9     medium         200       101          4           105         
10    medium         200       102          5           107         
11    slow           200       502          5           507         
12    slow           200       501          6           507         
13    slow           200       503          6           509         
14    slow           200       501          7           508         
15    slow           200       502          7           509         

统计：
--------------------------------------------------------------------------------
总请求数：           15
成功请求：           15
失败请求：           0
总墙上时间：         509 ms
所有持续时间总和：   3073 ms
最小请求持续时间：   11 ms
最大请求持续时间：   503 ms
平均请求持续时间：   204.87 ms

多路复用效率：
--------------------------------------------------------------------------------
并行化：             603.9%
加速因子：           6.04x
请求/秒：            29.47

可视化（时间线）：
--------------------------------------------------------------------------------
  1 |=
  2 |=
  3 |==
  4 |==
  5 |==
  6 |  ==========
  7 |  ==========
  8 |   ==========
  9 |   ==========
 10 |    ==========
 11 |    =================================================
 12 |     =================================================
 13 |     ==================================================
 14 |      =================================================
 15 |      ==================================================
    |----------------------------------------------------------------------|
    0                                                                  509ms
========================================
```

### 性能指标

**多路复用效率**：
- **并行化**：>600%（6x 加速）
- **加速因子**：6.04x
- **请求/秒**：~29.47

这表明 15 个请求在 ~509ms 内完成，而不是顺序执行的 ~3073ms - 显著的改进！

## API 端点

| 方法 | 路径 | 延迟 | 描述 |
|------|------|------|------|
| GET | `/` | - | 带文档的欢迎页面 |
| GET | `/fast` | 10ms | 快速响应端点 |
| GET | `/medium` | 100ms | 中等延迟端点 |
| GET | `/slow` | 500ms | 慢响应端点 |
| GET | `/random` | 10-500ms | 随机延迟端点 |
| GET | `/data/:size` | - | 生成指定 KB 大小的负载（最大 1MB） |
| GET | `/stats` | - | 服务器统计（请求、并发） |

## 代码亮点

### 服务器：并发请求跟踪

```cpp
struct RequestStats {
    std::atomic<uint64_t> total_requests{0};
    std::atomic<uint64_t> concurrent_requests{0};
    std::atomic<uint64_t> max_concurrent{0};
    
    void IncrementConcurrent() {
        uint64_t current = ++concurrent_requests;
        // 跟踪最大并发级别
        uint64_t max = max_concurrent.load();
        while (current > max && 
               !max_concurrent.compare_exchange_weak(max, current)) {
            max = max_concurrent.load();
        }
    }
};
```

### 服务器：模拟延迟

```cpp
// GET /slow - 慢响应（500ms）
server->AddHandler(
    quicx::http3::HttpMethod::kGet,
    "/slow",
    [stats](auto req, auto resp) {
        RAII_ConcurrentCounter counter(*stats);
        std::this_thread::sleep_for(std::chrono::milliseconds(500));
        // 响应...
    }
);
```

### 客户端：并发请求管理

```cpp
class ConcurrentTester {
    void SendRequest(int id, const std::string& endpoint, const std::string& url) {
        pending_requests_++;
        auto start = std::chrono::steady_clock::now();
        
        client_->DoRequest(url, quicx::http3::HttpMethod::kGet, request,
            [this, id, endpoint, start](auto response, uint32_t error) {
                auto end = std::chrono::steady_clock::now();
                auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(
                    end - start);
                
                // 存储带时间信息的结果
                RequestResult result{id, endpoint, start, end, duration.count()};
                results_.push_back(result);
                
                pending_requests_--;
            }
        );
    }
};
```

### 客户端：性能计算

```cpp
// 计算多路复用效率
double efficiency = (static_cast<double>(total_req_duration) / 
                     total_duration.count()) * 100.0;

double speedup = static_cast<double>(total_req_duration) / 
                 total_duration.count();

std::cout << "并行化: " << efficiency << "%" << std::endl;
std::cout << "加速因子: " << speedup << "x" << std::endl;
```

## 性能洞察

### HTTP/3 多路复用优势

1. **无队头阻塞**
   - 每个流都是独立的
   - 数据包丢失只影响一个流
   - 其他流继续不受影响

2. **连接效率**
   - 所有请求使用单个连接
   - 减少连接开销
   - 更好的资源利用

3. **延迟降低**
   - 并行请求处理
   - 更快的页面加载时间
   - 改善用户体验

### 真实世界场景

**网页加载**：
- HTML、CSS、JS、图片并行加载
- 慢图片不阻塞 CSS
- 渐进式渲染成为可能

**API 微服务**：
- 多个 API 调用同时进行
- 减少总响应时间
- 更好的吞吐量

**文件下载**：
- 多个文件并行下载
- 高效的带宽使用
- 无请求排队

## 测试场景

### 场景 1：混合工作负载
```bash
# 模拟具有各种资源类型的真实网页
15 个请求：快（HTML/CSS）+ 中（JS）+ 慢（图片）
结果：相比顺序执行 6x 加速
```

### 场景 2：API 网关
```bash
# 多个微服务调用
20 个随机延迟请求（模拟不同服务）
结果：高效处理可变延迟
```

### 场景 3：CDN 内容分发
```bash
# 不同大小的文件并发下载
10KB 到 1MB 文件并行
结果：最优带宽利用
```

### 场景 4：负载测试
```bash
# 增加负载下的可扩展性
10 → 25 → 50 → 100 并发请求
结果：线性吞吐量扩展
```

## 对比：HTTP/1.1 vs HTTP/3

| 指标 | HTTP/1.1 | HTTP/3 |
|------|----------|--------|
| 并发请求 | 有限（每域 6 个） | 无限制 |
| 队头阻塞 | 是（TCP 级别） | 否（QUIC 流） |
| 连接开销 | 高（多个连接） | 低（单个连接） |
| 请求排队 | 需要 | 不需要 |
| 延迟 | 较高 | 较低 |

## 生产环境注意事项

### 服务器优化
- **线程池大小**：根据预期并发配置
- **连接限制**：设置适当的最大并发流
- **资源管理**：监控负载下的内存/CPU
- **速率限制**：防止滥用

### 客户端最佳实践
- **连接池**：尽可能重用连接
- **请求优先级**：关键请求优先
- **超时管理**：设置适当的超时
- **错误处理**：使用退避重试失败的请求

### 监控
- 跟踪并发请求级别
- 监控响应时间分布
- 测量吞吐量（req/s）
- 性能下降时告警

## 故障排除

### 低并发
- 检查线程池配置
- 验证客户端/服务器线程数
- 查看连接限制

### 性能差
- 测量网络延迟
- 检查服务器 CPU/内存
- 查看请求模式

### 连接问题
- 验证 QUIC/UDP 未被阻止
- 检查防火墙设置
- 查看 MTU 设置

## 下一步

理解 HTTP/3 多路复用后：
1. 探索**流优先级**
2. 实现**请求合并**
3. 添加**连接迁移**
4. 构建**自适应流**

## 参考

- **HTTP/3 规范**：RFC 9114
- **QUIC 协议**：RFC 9000
- **多路复用**：vs HTTP/2 流
- **性能**：真实世界基准测试

## 许可证

本示例是 QuicX 项目的一部分。详见主 LICENSE 文件。


